<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="MagDiff is an end-to-end framework designed for identity-consistent video generation, demonstrating the capability to conduct direct inference when giving new entities without additional training. Moreover, through the control of quantities per image, it can enable image-to-video generation and video editing tasks.">
  <meta property="og:title" content="MagDiff: Multi-Alignment Diffusion for High-Fidelity Video Generation and Editing"/>
  <meta property="og:description" content="MagDiff is an end-to-end framework designed for identity-consistent video generation, demonstrating the capability to conduct direct inference when giving new entities without additional training. Moreover, through the control of quantities per image, it can enable image-to-video generation and video editing tasks."/>
  <meta property="og:url" content="#/"/>
  <meta property="og:image" content="static/image/magdiff_overview.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="MagDiff: Multi-Alignment Diffusion for High-Fidelity Video Generation and Editing">
  <meta name="twitter:description" content="MagDiff is an end-to-end framework designed for identity-consistent video generation, demonstrating the capability to conduct direct inference when giving new entities without additional training. Moreover, through the control of quantities per image, it can enable image-to-video generation and video editing tasks.">
  <meta name="twitter:image" content="static/images/magdiff_overview.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Video diffusion models, video editing, MagDiff, imagen-video">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="T_oFVFZUHiJACY9w641hFTTl5VlAQy8zkWTmyq1L3Z4" />


  <title>MagDiff: Multi-Alignment Diffusion for High-Fidelity Video Generation and Editing</title>
  <link rel="icon" type="image/x-icon" href="static/images/magdiff.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MagDiff: Multi-Alignment Diffusion for High-Fidelity Video Generation and Editing</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Haoyu Zhao, Tianyi Lu, Jiaxi Gu, Xing Zhang, Qingping Zheng, Zuxuan Wu, Hang Xu, and Yu-Gang Jiang
              </span>
            </div>
            
            <div class="is-size-5 publication-authors">
              <span class="author-block">Fudan University; Huawei Noah' Ark Lab</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2311.17338.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

            <!-- Github link -->
            <span class="link-block">
                <a href="https://github.com/gulucaptain/MagDiff" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>








<!-- Subject Driven Video Generation carousel -->
<section class="hero teaser">
      <div class="hero-body ">
    <div class="container is-max-desktop">
  
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video2">
          <video poster="" id="header-video2" autoplay muted loop playsinline height="100%" src="static/videos/volcano_is_erupting.mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            When presented with object's subject, MagDiff can generate videos preserving entity content with high fidelity. In the given example, an image of a mountain prompts the generation of a video showing the mountain transitioning into a volcanic eruption.
          </h2>
        </div>
        <div class="item item-video3">
          <video poster="" id="header-video3" autoplay muted loop playsinline height="100%"  src="static/videos/Robot_playing_piano.mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            MagDiff can edit the video based on video and text inputs. In this case, MagDiff successfully modified the robot's actions to playing the piano, and also edited the content and background accordingly.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Subject Driven Video Generation carousel -->







<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>The diffusion model is widely leveraged for either video generation or video editing. As each field has its task-specific problems, it is difficult to merely develop a single diffusion for completing both tasks simultaneously. Video diffusion sorely relying on the text prompt can be adapted to unify the two tasks. However, it lacks a high capability of aligning heterogeneous modalities between text and image, leading to various misalignment problems. In this work, we are the first to propose a unified Multi-alignment Diffusion, dubbed as MagDiff, for both tasks of high-fidelity video generation and editing. The proposed MagDiff introduces three types of alignments, including subject-driven alignment, adaptive prompts alignment, and high-fidelity alignment. Particularly, the subject-driven alignment is put forward to trade off the image and text prompts, serving as a unified foundation generative model for both tasks. The adaptive prompts alignment is introduced to emphasize different strengths of homogeneous and heterogeneous alignments by assigning different values of weights to the image and the text prompts. The high-fidelity alignment is developed to further enhance the fidelity of both video generation and editing by taking the subject image as an additional model input. Experimental results on four benchmarks suggest that our method outperforms the previous method on each task.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Vid2vid carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Generation with Input Entities</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="vid2vid_video1" playsinline autoplay muted loop height="90%" src="static/videos/panda_plays_water.mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="vid2vid_video2" playsinline autoplay muted loop height="90%" src="static/videos/teddy_bear_riding.mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="vid2vid_video3" playsinline autoplay muted loop height="90%" src="static/videos/squirrel_eating.mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="vid2vid_video4" playsinline autoplay muted loop height="90%" src="static/videos/dog_jumped_river.mp4">
          </video>
        </div>

        <div class="item item-video5">
          <video poster="" id="vid2vid_video5" playsinline autoplay muted loop height="90%" src="static/videos/panda_eats_bamboo.mp4">
          </video>
        </div>

        <div class="item item-video6">
          <video poster="" id="vid2vid_video6" playsinline autoplay muted loop height="90%" src="static/videos/Spiderman_turns_head.mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End vid2vid carousel -->


<!-- Img2vid carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Generation with Input Object's Entity</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="img2vid_video1" playsinline autoplay muted loop height="90%" src="static/videos/shoe_standing.mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="img2vid_video2" playsinline autoplay muted loop height="90%" src="static/videos/car_driving.mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="img2vid_video3" playsinline autoplay muted loop height="90%" src="static/videos/Doraemon_walking.mp4">
          </video>
        </div>

        <div class="item item-video4">
          <video poster="" id="img2vid_video4" playsinline autoplay muted loop height="90%" src="static/videos/man_holding_umbrella.mp4">
          </video>
        </div>

      <div class="item item-video5">
          <video poster="" id="img2vid_video5" playsinline autoplay muted loop height="90%" src="static/videos/sailboat_sailing.mp4">
          </video>
        </div>
      <div class="item item-video6">
          <video poster="" id="img2vid_video6" playsinline autoplay muted loop height="90%" src="static/videos/woman_stands.mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End img2vid carousel -->


<!-- Subject Driven Video Generation carousel -->
<section class="hero is-small">
  <div class="hero-body ">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Editing with Input Video</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="sd_video1" playsinline autoplay muted loop height="90%" src="static/videos/unicorn_sprints.mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="sd_video2" playsinline autoplay muted loop height="90%" src="static/videos/eagle_lands.mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="sd_video3" playsinline autoplay muted loop height="90%" src="static/videos/skeleton_burning.mp4">
          </video>
        </div>
        <div class="item item-video4">
          <video poster="" id="sd_video4" playsinline autoplay muted loop height="90%" src="static/videos/phoenix_files.mp4">
          </video>
        </div>
        <div class="item item-video5">
          <video poster="" id="sd_video5" playsinline autoplay muted loop height="90%" src="static/videos/ghost_floating.mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Subject Driven Video Generation carousel -->



<section class="section hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Method Overview:</h2>
          <center>
          <img src="static/images/magdiff_overview.png" alt="Mixed Video-Image Finetuning" class="center-image blend-img-background"/>
          </center>
          <div class="level-set has-text-justified">
            <p>An overview of our proposed Multi-alignment Diffusion (MagDiff), a unified diffusion method supporting both video generation and editing at the same time. Our MagDiff is comprised of three key components: 1. Subject-Driven Alignment (SDA) for unifying two tasks, 2. Adaptive Prompts Alignment (APA) for distinguishing the different controllability between homogeneous and heterogeneous modalities, and 3. High-Fidelity Alignment (HFA) for improving the quality of video generation or editing.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhao2024magdiff,
  title={MagDiff: Multi-Alignment Diffusion for High-Fidelity Video Generation and Editing},
  author={Zhao, Haoyu and Lu, Tianyi and Gu, Jiaxi and Zhang, Xing and Zheng, Qingping and Wu, Zuxuan and Xu, Hang and Jiang Yu-Gang},
  journal={ECCV},
  year={2024}
}</code></pre>
  </div>
</section>
<!-- End BibTex citation -->
  
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<script type="text/javascript">
var sc_project=12843789; 
var sc_invisible=1; 
var sc_security="e9c3bf5f"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12843789/0/e9c3bf5f/1/"
alt="Web Analytics"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>

<!-- End of Statcounter Code -->

</body>
</html>
